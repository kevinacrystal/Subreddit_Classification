{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kevinc/anaconda3/lib/python3.6/site-packages/sklearn/ensemble/weight_boosting.py:29: DeprecationWarning: numpy.core.umath_tests is an internal NumPy module and should not be imported. It will be removed in a future NumPy release.\n",
      "  from numpy.core.umath_tests import inner1d\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier, BaggingClassifier, AdaBoostClassifier\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subreddit</th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>WritingPrompts</td>\n",
       "      <td>It's been over 800 days since you landed on P...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>WritingPrompts</td>\n",
       "      <td>Humans are the only species known to have dom...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>WritingPrompts</td>\n",
       "      <td>He has been blind all his life. Now, he is th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>WritingPrompts</td>\n",
       "      <td>You’re dying...and dying. And then you die. B...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>WritingPrompts</td>\n",
       "      <td>Humanity has found a way to circumvent the ne...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        subreddit                                              title\n",
       "0  WritingPrompts   It's been over 800 days since you landed on P...\n",
       "1  WritingPrompts   Humans are the only species known to have dom...\n",
       "2  WritingPrompts   He has been blind all his life. Now, he is th...\n",
       "3  WritingPrompts   You’re dying...and dying. And then you die. B...\n",
       "4  WritingPrompts   Humanity has found a way to circumvent the ne..."
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import the combined dataframe\n",
    "# and check out the first five rows\n",
    "df = pd.read_csv('./datasets/combined_df.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Showerthoughts    998\n",
       "WritingPrompts    998\n",
       "Name: subreddit, dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check out the distribution of the target column\n",
    "df.subreddit.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre-Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenize and Stem all of the Titles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import tokenizer and stemmer\n",
    "from nltk import word_tokenize\n",
    "from nltk.stem import PorterStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a function that takes in a title\n",
    "# and tokenizes and stems that title\n",
    "def stem_title(title):    \n",
    "    stm = PorterStemmer()\n",
    "    tokenized = word_tokenize(title)\n",
    "    stem_tokes = []\n",
    "    for toke in tokenized:\n",
    "        stem_tokes.append(stm.stem(toke))\n",
    "    stem_tokes\n",
    "\n",
    "    comb = ''\n",
    "    for stemmed in stem_tokes:\n",
    "        comb += stemmed + ' '\n",
    "    return comb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'you ’ re die ... and die . and then you die . but you wake up . you ’ re now an anim . you ’ ve start to enjoy thi second life . '"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check that the function works\n",
    "stem_title(df.title[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subreddit</th>\n",
       "      <th>title</th>\n",
       "      <th>stemmed_titles</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>WritingPrompts</td>\n",
       "      <td>It's been over 800 days since you landed on P...</td>\n",
       "      <td>It 's been over 800 day sinc you land on plane...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>WritingPrompts</td>\n",
       "      <td>Humans are the only species known to have dom...</td>\n",
       "      <td>human are the onli speci known to have domest ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>WritingPrompts</td>\n",
       "      <td>He has been blind all his life. Now, he is th...</td>\n",
       "      <td>He ha been blind all hi life . now , he is the...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>WritingPrompts</td>\n",
       "      <td>You’re dying...and dying. And then you die. B...</td>\n",
       "      <td>you ’ re die ... and die . and then you die . ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>WritingPrompts</td>\n",
       "      <td>Humanity has found a way to circumvent the ne...</td>\n",
       "      <td>human ha found a way to circumv the need for s...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        subreddit                                              title  \\\n",
       "0  WritingPrompts   It's been over 800 days since you landed on P...   \n",
       "1  WritingPrompts   Humans are the only species known to have dom...   \n",
       "2  WritingPrompts   He has been blind all his life. Now, he is th...   \n",
       "3  WritingPrompts   You’re dying...and dying. And then you die. B...   \n",
       "4  WritingPrompts   Humanity has found a way to circumvent the ne...   \n",
       "\n",
       "                                      stemmed_titles  \n",
       "0  It 's been over 800 day sinc you land on plane...  \n",
       "1  human are the onli speci known to have domest ...  \n",
       "2  He ha been blind all hi life . now , he is the...  \n",
       "3  you ’ re die ... and die . and then you die . ...  \n",
       "4  human ha found a way to circumv the need for s...  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create a new column by applying the function to the title column\n",
    "# and check out the head to see if it worked\n",
    "df['stemmed_titles'] = df.title.apply(stem_title)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subreddit</th>\n",
       "      <th>title</th>\n",
       "      <th>stemmed_titles</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1991</th>\n",
       "      <td>Showerthoughts</td>\n",
       "      <td>The fact that we have collectively decided to ...</td>\n",
       "      <td>the fact that we have collect decid to trick a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1992</th>\n",
       "      <td>Showerthoughts</td>\n",
       "      <td>\"Leaving the sinking ship\" fit metaphoricly pe...</td>\n",
       "      <td>`` leav the sink ship '' fit metaphoricli perf...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1993</th>\n",
       "      <td>Showerthoughts</td>\n",
       "      <td>If you could lift objects with your mind, you ...</td>\n",
       "      <td>If you could lift object with your mind , you ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1994</th>\n",
       "      <td>Showerthoughts</td>\n",
       "      <td>In the one episode of Phineas and Ferb where F...</td>\n",
       "      <td>In the one episod of phinea and ferb where fer...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1995</th>\n",
       "      <td>Showerthoughts</td>\n",
       "      <td>If Final Fantasy ever reaches the 30th main ga...</td>\n",
       "      <td>If final fantasi ever reach the 30th main game...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           subreddit                                              title  \\\n",
       "1991  Showerthoughts  The fact that we have collectively decided to ...   \n",
       "1992  Showerthoughts  \"Leaving the sinking ship\" fit metaphoricly pe...   \n",
       "1993  Showerthoughts  If you could lift objects with your mind, you ...   \n",
       "1994  Showerthoughts  In the one episode of Phineas and Ferb where F...   \n",
       "1995  Showerthoughts  If Final Fantasy ever reaches the 30th main ga...   \n",
       "\n",
       "                                         stemmed_titles  \n",
       "1991  the fact that we have collect decid to trick a...  \n",
       "1992  `` leav the sink ship '' fit metaphoricli perf...  \n",
       "1993  If you could lift object with your mind , you ...  \n",
       "1994  In the one episod of phinea and ferb where fer...  \n",
       "1995  If final fantasi ever reach the 30th main game...  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check out the tail, too\n",
    "df.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Prep"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set up X and y Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.stemmed_titles\n",
    "y = df.subreddit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train-Test-Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, \n",
    "                                                    stratify=y, \n",
    "                                                    random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TfidfVectorize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate\n",
    "tf = TfidfVectorizer(stop_words='english', \n",
    "                     ngram_range=(1,2), \n",
    "                     max_features=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit and Transform the training data\n",
    "X_train_tf = tf.fit_transform(X_train)\n",
    "\n",
    "# Transform the test data\n",
    "X_test_tf = tf.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define a function to automate the following steps:\n",
    "1. Instantiate\n",
    "2. Fit to training data\n",
    "3. Score on the training data\n",
    "4. Score on the test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def default_classifier(classifier):\n",
    "    # Instantiate\n",
    "    clf = classifier()\n",
    "    \n",
    "    # Fit to the training data\n",
    "    clf.fit(X_train_tf, y_train)\n",
    "    \n",
    "    # Score on the training data\n",
    "    print(f'Training Score: {clf.score(X_train_tf, y_train)}')\n",
    "\n",
    "    # Score on the test data\n",
    "    print(f'Test Score: {clf.score(X_test_tf, y_test)}')\n",
    "    \n",
    "    # Return the parameters of the classifier,\n",
    "    # so I have a basis for sampling GridSearch parameters\n",
    "    return clf.get_params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dummy Classifier\n",
    "I'm running a Dummy classifier to get a sense of my baseline. Since the classes are perfectly balanced (50/50), it's unsurprising that the Dummy classifier scores are around 50 percent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Score: 0.4909819639278557\n",
      "Test Score: 0.531062124248497\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kevinc/anaconda3/lib/python3.6/site-packages/sklearn/dummy.py:227: FutureWarning: arrays to stack must be passed as a \"sequence\" type such as list or tuple. Support for non-sequence iterables such as generators is deprecated as of NumPy 1.16 and will raise an error in the future.\n",
      "  k in range(self.n_outputs_)).T\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<bound method BaseEstimator.get_params of DummyClassifier(constant=None, random_state=None, strategy='stratified')>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "default_classifier(DummyClassifier)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Naive Bayes Classifier (default parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Score: 0.8964595858383434\n",
      "Test Score: 0.781563126252505\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<bound method BaseEstimator.get_params of MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "default_classifier(MultinomialNB)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Naive Bayes Classifier (alternate parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score on training set: 0.9111556446225785\n",
      "Score on testing set: 0.7675350701402806\n"
     ]
    }
   ],
   "source": [
    "mnb = MultinomialNB(alpha=0.1)\n",
    "mnb.fit(X_train_tf, y_train)\n",
    "print(f'Score on training set: {mnb.score(X_train_tf, y_train)}')\n",
    "print(f'Score on testing set: {mnb.score(X_test_tf, y_test)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Logistic Regression Classifier (default parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Score: 0.9258517034068137\n",
      "Test Score: 0.8356713426853707\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<bound method BaseEstimator.get_params of LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "default_classifier(LogisticRegression)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Logistic Regression Classifier (alternate parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score on training set: 0.8717434869739479\n",
      "Score on testing set: 0.8236472945891784\n"
     ]
    }
   ],
   "source": [
    "clf = LogisticRegression(C=0.1)\n",
    "clf.fit(X_train_tf, y_train)\n",
    "print(f'Score on training set: {clf.score(X_train_tf, y_train)}')\n",
    "print(f'Score on testing set: {clf.score(X_test_tf, y_test)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### DecisionTree Classifier (default parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Score: 0.9993319973279893\n",
      "Test Score: 0.7334669338677354\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<bound method BaseEstimator.get_params of DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
       "            max_features=None, max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
       "            splitter='best')>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "default_classifier(DecisionTreeClassifier)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### DecisionTree Classifier (GridSearch parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score on training set: 0.9418837675350702\n",
      "Score on testing set: 0.7114228456913828\n"
     ]
    }
   ],
   "source": [
    "# Instantiate the GridSearch\n",
    "grid = GridSearchCV(estimator=DecisionTreeClassifier(),\n",
    "                    param_grid={'max_depth': [None, 3, 10, 20],\n",
    "                                'min_samples_leaf': [1, 2, 3],\n",
    "                                'min_samples_split': [2, 3, 4]},\n",
    "                    cv=3)\n",
    "\n",
    "# Fit the GridSearch on the training data\n",
    "grid.fit(X_train_tf, y_train)\n",
    "\n",
    "# Instantiate the RandomForest classifier with the best parameters\n",
    "dt = DecisionTreeClassifier(max_depth= grid.best_params_['max_depth'],\n",
    "                            min_samples_leaf= grid.best_params_['min_samples_leaf'],\n",
    "                            min_samples_split= grid.best_params_['min_samples_split'])\n",
    "\n",
    "# Fit the classifier to the training data\n",
    "dt.fit(X_train_tf, y_train)\n",
    "\n",
    "# Evaluate model.\n",
    "print(f'Score on training set: {dt.score(X_train_tf, y_train)}')\n",
    "print(f'Score on testing set: {dt.score(X_test_tf, y_test)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### RandomForest Classifier (default parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Score: 0.9879759519038076\n",
      "Test Score: 0.8136272545090181\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<bound method BaseEstimator.get_params of RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False)>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fit using the default parameters\n",
    "default_classifier(RandomForestClassifier)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### RandomForest Classifier (GridSearch parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score on training set: 0.9258517034068137\n",
      "Score on testing set: 0.8276553106212425\n"
     ]
    }
   ],
   "source": [
    "# Instantiate the GridSearch\n",
    "grid = GridSearchCV(estimator=RandomForestClassifier(),\n",
    "                    param_grid={'max_depth': [None, 3, 10, 20],\n",
    "                                'min_samples_leaf': [1, 2, 3],\n",
    "                                'min_samples_split': [2, 3, 4],\n",
    "                                'n_estimators': [10, 20, 30]},\n",
    "                    cv=3)\n",
    "\n",
    "# Fit the GridSearch on the training data\n",
    "grid.fit(X_train_tf, y_train)\n",
    "\n",
    "# Instantiate the RandomForest classifier with the best parameters\n",
    "rf = RandomForestClassifier(max_depth= grid.best_params_['max_depth'],\n",
    "                            min_samples_leaf= grid.best_params_['min_samples_leaf'],\n",
    "                            min_samples_split= grid.best_params_['min_samples_split'],\n",
    "                            n_estimators= grid.best_params_['n_estimators'])\n",
    "\n",
    "# Fit the classifier to the training data\n",
    "rf.fit(X_train_tf, y_train)\n",
    "\n",
    "# Evaluate model.\n",
    "print(f'Score on training set: {rf.score(X_train_tf, y_train)}')\n",
    "print(f'Score on testing set: {rf.score(X_test_tf, y_test)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Support Vector Classifier (default parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Score: 0.5003340013360054\n",
      "Test Score: 0.49899799599198397\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<bound method BaseEstimator.get_params of SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='rbf',\n",
       "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "  tol=0.001, verbose=False)>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "default_classifier(SVC)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Support Vector Classifier (alternate parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score on training set: 0.9385437541750167\n",
      "Score on testing set: 0.8256513026052105\n"
     ]
    }
   ],
   "source": [
    "svc_2 = SVC(kernel='linear')\n",
    "svc_2.fit(X_train_tf, y_train)\n",
    "print(f'Score on training set: {svc_2.score(X_train_tf, y_train)}')\n",
    "print(f'Score on testing set: {svc_2.score(X_test_tf, y_test)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score on training set: 0.8670674682698731\n",
      "Score on testing set: 0.8236472945891784\n"
     ]
    }
   ],
   "source": [
    "svc_3 = SVC(kernel='linear', C=0.1)\n",
    "svc_3.fit(X_train_tf, y_train)\n",
    "print(f'Score on training set: {svc_3.score(X_train_tf, y_train)}')\n",
    "print(f'Score on testing set: {svc_3.score(X_test_tf, y_test)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### K Nearest Neighbors Classifier (default parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Score: 0.5263861055444222\n",
      "Test Score: 0.503006012024048\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<bound method BaseEstimator.get_params of KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "           metric_params=None, n_jobs=1, n_neighbors=5, p=2,\n",
       "           weights='uniform')>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "default_classifier(KNeighborsClassifier)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### K Nearest Neighbors Classifier (alternate parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score on training set: 0.5337341349365398\n",
      "Score on testing set: 0.503006012024048\n"
     ]
    }
   ],
   "source": [
    "knn2 = KNeighborsClassifier(n_neighbors=3)\n",
    "knn2.fit(X_train_tf, y_train)\n",
    "print(f'Score on training set: {knn2.score(X_train_tf, y_train)}')\n",
    "print(f'Score on testing set: {knn2.score(X_test_tf, y_test)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score on training set: 0.5290581162324649\n",
      "Score on testing set: 0.5070140280561122\n"
     ]
    }
   ],
   "source": [
    "knn3 = KNeighborsClassifier(n_neighbors=2)\n",
    "knn3.fit(X_train_tf, y_train)\n",
    "print(f'Score on training set: {knn3.score(X_train_tf, y_train)}')\n",
    "print(f'Score on testing set: {knn3.score(X_test_tf, y_test)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Bagging Classifier (Default Parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Score: 0.9886439545758183\n",
      "Test Score: 0.7875751503006012\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<bound method BaseEstimator.get_params of BaggingClassifier(base_estimator=None, bootstrap=True,\n",
       "         bootstrap_features=False, max_features=1.0, max_samples=1.0,\n",
       "         n_estimators=10, n_jobs=1, oob_score=False, random_state=None,\n",
       "         verbose=0, warm_start=False)>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "default_classifier(BaggingClassifier)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### AdaBoost Classifier (Default Parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Score: 0.832999331997328\n",
      "Test Score: 0.7535070140280561\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<bound method BaseEstimator.get_params of AdaBoostClassifier(algorithm='SAMME.R', base_estimator=None,\n",
       "          learning_rate=1.0, n_estimators=50, random_state=None)>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "default_classifier(AdaBoostClassifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
