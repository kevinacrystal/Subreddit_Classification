{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kevinc/anaconda3/lib/python3.6/site-packages/sklearn/ensemble/weight_boosting.py:29: DeprecationWarning: numpy.core.umath_tests is an internal NumPy module and should not be imported. It will be removed in a future NumPy release.\n",
      "  from numpy.core.umath_tests import inner1d\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subreddit</th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>WritingPrompts</td>\n",
       "      <td>It's been over 800 days since you landed on P...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>WritingPrompts</td>\n",
       "      <td>Humans are the only species known to have dom...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>WritingPrompts</td>\n",
       "      <td>He has been blind all his life. Now, he is th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>WritingPrompts</td>\n",
       "      <td>You’re dying...and dying. And then you die. B...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>WritingPrompts</td>\n",
       "      <td>Humanity has found a way to circumvent the ne...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        subreddit                                              title\n",
       "0  WritingPrompts   It's been over 800 days since you landed on P...\n",
       "1  WritingPrompts   Humans are the only species known to have dom...\n",
       "2  WritingPrompts   He has been blind all his life. Now, he is th...\n",
       "3  WritingPrompts   You’re dying...and dying. And then you die. B...\n",
       "4  WritingPrompts   Humanity has found a way to circumvent the ne..."
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import the combined dataframe\n",
    "# and check out the first five rows\n",
    "df = pd.read_csv('./datasets/combined_df.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Showerthoughts    998\n",
       "WritingPrompts    998\n",
       "Name: subreddit, dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check out the distribution of the target column\n",
    "df.subreddit.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lemmatize all of the words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['it', 's', 'been', 'over', '800', 'day', 'since', 'you', 'landed', 'on']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words = ''\n",
    "for entry in df.title:\n",
    "    words += entry\n",
    "\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "tokenizer = RegexpTokenizer(r'\\w+')\n",
    "word_tokens = tokenizer.tokenize(words.lower())\n",
    "\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "words_lem = [lemmatizer.lemmatize(i) for i in word_tokens]\n",
    "\n",
    "words_lem[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Prep"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set up X and y Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.title\n",
    "y = df.subreddit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train-Test-Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, \n",
    "                                                    stratify=y, \n",
    "                                                    random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CountVectorize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate\n",
    "cv = CountVectorizer(stop_words='english', \n",
    "                     ngram_range=(1,2), \n",
    "                     max_features=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit and Transform the training data\n",
    "X_train_cv = cv.fit_transform(X_train)\n",
    "\n",
    "# Transform the test data\n",
    "X_test_cv = cv.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define a function to automate the following steps:\n",
    "1. Instantiate\n",
    "2. Fit to training data\n",
    "3. Score on the training data\n",
    "4. Score on the test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def default_classifier(classifier):\n",
    "    # Instantiate\n",
    "    clf = classifier()\n",
    "    \n",
    "    # Fit to the training data\n",
    "    clf.fit(X_train_cv, y_train)\n",
    "    \n",
    "    # Score on the training data\n",
    "    print(f'Training Score: {clf.score(X_train_cv, y_train)}')\n",
    "\n",
    "    # Score on the test data\n",
    "    print(f'Test Score: {clf.score(X_test_cv, y_test)}')\n",
    "    \n",
    "    # Return the parameters of the classifier,\n",
    "    # so I have a basis for sampling GridSearch parameters\n",
    "    return clf.get_params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dummy Classifier\n",
    "I'm running a Dummy classifier to get a sense of my baseline. Since the classes are perfectly balanced (50/50), it's unsurprising that the Dummy classifier scores are around 50 percent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Score: 0.509686038744155\n",
      "Test Score: 0.5130260521042084\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kevinc/anaconda3/lib/python3.6/site-packages/sklearn/dummy.py:227: FutureWarning: arrays to stack must be passed as a \"sequence\" type such as list or tuple. Support for non-sequence iterables such as generators is deprecated as of NumPy 1.16 and will raise an error in the future.\n",
      "  k in range(self.n_outputs_)).T\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<bound method BaseEstimator.get_params of DummyClassifier(constant=None, random_state=None, strategy='stratified')>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "default_classifier(DummyClassifier)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Naive Bayes Classifier (default parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Score: 0.8730794923179692\n",
      "Test Score: 0.7314629258517034\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<bound method BaseEstimator.get_params of MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "default_classifier(MultinomialNB)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Naive Bayes Classifier (alternate parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score on training set: 0.8891115564462257\n",
      "Score on testing set: 0.7394789579158316\n"
     ]
    }
   ],
   "source": [
    "mnb = MultinomialNB(alpha=0.1)\n",
    "mnb.fit(X_train_cv, y_train)\n",
    "print(f'Score on training set: {mnb.score(X_train_cv, y_train)}')\n",
    "print(f'Score on testing set: {mnb.score(X_test_cv, y_test)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Logistic Regression Classifier (default parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Score: 0.9579158316633266\n",
      "Test Score: 0.8176352705410822\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<bound method BaseEstimator.get_params of LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "default_classifier(LogisticRegression)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Logistic Regression Classifier (alternate parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score on training set: 0.8804275217100869\n",
      "Score on testing set: 0.8176352705410822\n"
     ]
    }
   ],
   "source": [
    "clf = LogisticRegression(C=0.1)\n",
    "clf.fit(X_train_cv, y_train)\n",
    "print(f'Score on training set: {clf.score(X_train_cv, y_train)}')\n",
    "print(f'Score on testing set: {clf.score(X_test_cv, y_test)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### DecisionTree Classifier (default parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Score: 0.9979959919839679\n",
      "Test Score: 0.7535070140280561\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<bound method BaseEstimator.get_params of DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
       "            max_features=None, max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
       "            splitter='best')>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "default_classifier(DecisionTreeClassifier)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### DecisionTree Classifier (GridSearch parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score on training set: 0.9766199064796259\n",
      "Score on testing set: 0.7755511022044088\n"
     ]
    }
   ],
   "source": [
    "# Instantiate the GridSearch\n",
    "grid = GridSearchCV(estimator=DecisionTreeClassifier(),\n",
    "                    param_grid={'max_depth': [None, 3, 10, 20],\n",
    "                                'min_samples_leaf': [1, 2, 3],\n",
    "                                'min_samples_split': [2, 3, 4]},\n",
    "                    cv=3)\n",
    "\n",
    "# Fit the GridSearch on the training data\n",
    "grid.fit(X_train_cv, y_train)\n",
    "\n",
    "# Instantiate the RandomForest classifier with the best parameters\n",
    "dt = DecisionTreeClassifier(max_depth= grid.best_params_['max_depth'],\n",
    "                            min_samples_leaf= grid.best_params_['min_samples_leaf'],\n",
    "                            min_samples_split= grid.best_params_['min_samples_split'])\n",
    "\n",
    "# Fit the classifier to the training data\n",
    "dt.fit(X_train_cv, y_train)\n",
    "\n",
    "# Evaluate model.\n",
    "print(f'Score on training set: {dt.score(X_train_cv, y_train)}')\n",
    "print(f'Score on testing set: {dt.score(X_test_cv, y_test)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### RandomForest Classifier (default parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Score: 0.9812959251837008\n",
      "Test Score: 0.7474949899799599\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<bound method BaseEstimator.get_params of RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False)>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fit using the default parameters\n",
    "default_classifier(RandomForestClassifier)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### RandomForest Classifier (GridSearch parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score on training set: 0.9799599198396793\n",
      "Score on testing set: 0.7895791583166333\n"
     ]
    }
   ],
   "source": [
    "# Instantiate the GridSearch\n",
    "grid = GridSearchCV(estimator=RandomForestClassifier(),\n",
    "                    param_grid={'max_depth': [None, 3, 10, 20],\n",
    "                                'min_samples_leaf': [1, 2, 3],\n",
    "                                'min_samples_split': [2, 3, 4],\n",
    "                                'n_estimators': [10, 20, 30]},\n",
    "                    cv=3)\n",
    "\n",
    "# Fit the GridSearch on the training data\n",
    "grid.fit(X_train_cv, y_train)\n",
    "\n",
    "# Instantiate the RandomForest classifier with the best parameters\n",
    "rf = RandomForestClassifier(max_depth= grid.best_params_['max_depth'],\n",
    "                            min_samples_leaf= grid.best_params_['min_samples_leaf'],\n",
    "                            min_samples_split= grid.best_params_['min_samples_split'],\n",
    "                            n_estimators= grid.best_params_['n_estimators'])\n",
    "\n",
    "# Fit the classifier to the training data\n",
    "rf.fit(X_train_cv, y_train)\n",
    "\n",
    "# Evaluate model.\n",
    "print(f'Score on training set: {rf.score(X_train_cv, y_train)}')\n",
    "print(f'Score on testing set: {rf.score(X_test_cv, y_test)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Support Vector Classifier (default parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Score: 0.5003340013360054\n",
      "Test Score: 0.49899799599198397\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<bound method BaseEstimator.get_params of SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='rbf',\n",
       "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "  tol=0.001, verbose=False)>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "default_classifier(SVC)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Support Vector Classifier (alternate parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score on training set: 0.9759519038076152\n",
      "Score on testing set: 0.8016032064128257\n"
     ]
    }
   ],
   "source": [
    "svc_2 = SVC(kernel='linear')\n",
    "svc_2.fit(X_train_cv, y_train)\n",
    "print(f'Score on training set: {svc_2.score(X_train_cv, y_train)}')\n",
    "print(f'Score on testing set: {svc_2.score(X_test_cv, y_test)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score on training set: 0.8991315965263861\n",
      "Score on testing set: 0.8196392785571143\n"
     ]
    }
   ],
   "source": [
    "svc_3 = SVC(kernel='linear', C=0.1)\n",
    "svc_3.fit(X_train_cv, y_train)\n",
    "print(f'Score on training set: {svc_3.score(X_train_cv, y_train)}')\n",
    "print(f'Score on testing set: {svc_3.score(X_test_cv, y_test)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### K Nearest Neighbors Classifier (default parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Score: 0.5784903139612558\n",
      "Test Score: 0.5290581162324649\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<bound method BaseEstimator.get_params of KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "           metric_params=None, n_jobs=1, n_neighbors=5, p=2,\n",
       "           weights='uniform')>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "default_classifier(KNeighborsClassifier)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### K Nearest Neighbors Classifier (alternate parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score on training set: 0.6199064796259185\n",
      "Score on testing set: 0.5390781563126252\n"
     ]
    }
   ],
   "source": [
    "knn2 = KNeighborsClassifier(n_neighbors=3)\n",
    "knn2.fit(X_train_cv, y_train)\n",
    "print(f'Score on training set: {knn2.score(X_train_cv, y_train)}')\n",
    "print(f'Score on testing set: {knn2.score(X_test_cv, y_test)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score on training set: 0.5918503674014696\n",
      "Score on testing set: 0.5290581162324649\n"
     ]
    }
   ],
   "source": [
    "knn3 = KNeighborsClassifier(n_neighbors=2)\n",
    "knn3.fit(X_train_cv, y_train)\n",
    "print(f'Score on training set: {knn3.score(X_train_cv, y_train)}')\n",
    "print(f'Score on testing set: {knn3.score(X_test_cv, y_test)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
